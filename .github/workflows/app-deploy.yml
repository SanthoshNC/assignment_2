name: App Deployment Pipeline
run-name: ${{ github.actor }} is running the app deployment pipeline ðŸš€

on:
  workflow_dispatch:
#on:
#  push:
#    branches:
#      - main
#    paths:
#      - app/**

env:
  LOG_GROUP_NAME: ${{ vars.CLOUDWATCH_LOG_GROUP }}

jobs:
  app-deployment-pipeline:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: app
        
    steps:
      - name: Checkout the code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

    ## Secret Scanning
      - name: Git Secret Scanning
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    ## SAST Scanning
      - name: SonarCloud Scan
        uses: sonarsource/sonarcloud-github-action@v3.0.0
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          projectBaseDir: app
          args: >
                -Dsonar.organization=santhosh-devops-demo
                -Dsonar.projectKey=santhosh-devops-demo_scb-assignment
                -Dsonar.sources=.
                -Dsonar.verbose=true

      - name: Docker Build
        run: docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/hello-app .   

      - name: Docker Images
        run: docker images
        
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.20.0
        with:
          image-ref: 'docker.io/santhoshnc/hello-app:latest'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
          
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}

      - name: Docker Push
        run: docker push ${{ secrets.DOCKERHUB_USERNAME }}/hello-app

      - name: Download 24hrs Old Logs
        uses: pawanbahuguna/action-logs/@v1.0.1
        env: 
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GH_REPO: ${{ github.repository }}
          
      - name: list files
        working-directory: .
        run: ls -lrt
        
      - name: list files in jobs-log
        working-directory: .
        run: ls -lrt jobs-log
        
      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Create job-logs-json directory
        working-directory: .
        run: mkdir -p job-logs-json

      - name: Convert First TXT to JSON
        working-directory: .
        id: convert
        run: |
          # Get the first .txt file
          file=$(ls jobs-log/*.txt | head -n 1)
          filename=$(basename "$file" .txt)
          
          # Read the file, escape characters, and convert to JSON
          log_message=$(tr '\n' '\\n' < "$file" | sed 's/"/\\"/g')
          echo "{\"log\": \"$log_message\"}" > "job-logs-json/${filename}.json"

          # Output the filename for the next step
          echo "Converted JSON file: job-logs-json/${filename}.json"
          echo "json_file_path=job-logs-json/${filename}.json" >> $GITHUB_ENV

      - name: Upload JSON to CloudWatch
        working-directory: .
        run: |
          log_group_name="${{ env.LOG_GROUP_NAME }}"
          current_date=$(date +%Y-%m-%d)
          log_stream_name="log-stream-$current_date"
          
          # Create log group if it does not exist
          aws logs create-log-group --log-group-name "$log_group_name" || true
          
          # Create log stream if it does not exist
          aws logs create-log-stream --log-group-name "$log_group_name" --log-stream-name "$log_stream_name" || true

          # Prepare log events
          timestamp=$(date +%s%3N)
          message=$(cat ${{ env.json_file_path }} | jq -Rsa .)
          
          log_events="{\"timestamp\": $timestamp, \"message\": $message}"

          # Put logs into CloudWatch
          aws logs put-log-events \
            --log-group-name "$log_group_name" \
            --log-stream-name "$log_stream_name" \
            --log-events "$log_events"
